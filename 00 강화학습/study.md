# 강화학습 공부 
출처 : https://www.edwith.org/move37/lecture/59774?isDesc=false

### 지도 학습
- 어떤 값을 예측
- 값이 이미 데이터 속에 존재 - 레이블, 타겟 변수, 종속 변수
- 이외의 특성 - 독립 변수
- 선형 회귀, 로지스텍 회귀, 신경망, 결정트리 - 입력값을 가지고 레이블을 알아내는 함수

### 비지도 학습
- 사용할 수 있는 레이블이 없는 경우
- K-means, 혼합 모델
- 데이터를 그룹으로 묶어 시각화하고 연관성 파악
- 데이터 축약해서 표현 - 오토 인코더
- 데이터 전처리에 주로 사용

### 마르코프 체인
- 어떠한 상태에서 다른 상태로 연속적으로 이동할 수 있는 상태들의 집합이 있다고 가정
- 각각의 이동은 한단계로만 되어있고 'T'라는 전이 모델을 기반으로 함
- 'T'는 어떻게 하나의 상태에서 다른 상태로 이동할 수 있는지를 정의
- 현재 상태가 주어졌을 때 미래는 과거와 조건부 독립이라는 것으로 현재 진행중인 상태는 딱 한 단계전의 상태에만 의존한다
- 가장 일반적으로 어떤 환경 내 에이전트의 학습을 강화학습의 문제로 표현하는 방식이 마르코프 결정 과정

#### 마르코프 결정 과정의 요소
- 상태 집합
- 초기 상태
- 행동 집합
- 전이 모델 - 다음 상태에 도달할 수 있는 확률
- 보상 함수 - R(s,a)

# 벨만 방정식
- State - 에이전트가 환경의 특정 시점에서 관찰하고 있는 것을 숫자로 표현한 것
- Action - 현재 상태에 정책을 적용하여 계산된 에이전트가 환경에 제공하는 입력
- Reward - 에이전트가 게임의 목표를 얼마나 잘 수행하고 있는지를 반영하는 환경의 피드백 신호
